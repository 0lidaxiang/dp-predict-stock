{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import requests\n",
    "import json\n",
    "# from newsapi import NewsApiClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news api key : \n",
    "# 16111b4976684a4b8f07dedf332b8e60\n",
    "\n",
    "# {'id': 'cnbc', 'url': 'http://www.cnbc.com',\n",
    "#  'description': 'Get latest business news on stock markets, financial & earnings on CNBC. View world markets streaming charts & video; check stock tickers and quotes.', \n",
    "#  'name': 'CNBC', 'country': 'us', 'category': 'business', 'language': 'en'}, \n",
    "\n",
    "# Init\n",
    "API_KEY = \"16111b4976684a4b8f07dedf332b8e60\"\n",
    "# newsapi = NewsApiClient(api_key= API_KEY)\n",
    "\n",
    "# /v2/sources\n",
    "# sources = newsapi.get_sources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get everything\n",
    "# /v2/top-headlines\n",
    "page_num = 1\n",
    "page_size = 100\n",
    "\n",
    "url_params = {\"q\":\"google\", \"page\": page_num, \"pageSize\": page_size, \"apiKey\": API_KEY}\n",
    "\n",
    "everything_url=\"https://newsapi.org/v2/everything?\"\n",
    "r = requests.get(everything_url, params=url_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status:  ok  | totalResults:  334614  | page_num:  1  | page_size:  100\n",
      "articles_type :  <class 'list'> articles_len :  100\n",
      "CPU times: user 1.55 ms, sys: 0 ns, total: 1.55 ms\n",
      "Wall time: 1.42 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rtext = json.loads(r.text)\n",
    "\n",
    "status = rtext[\"status\"]\n",
    "articles = rtext[\"articles\"]\n",
    "totalResults = rtext[\"totalResults\"]\n",
    "\n",
    "print(\"status: \", status, \" | totalResults: \", totalResults, \" | page_num: \", page_num, \" | page_size: \", page_size)\n",
    "articles = rtext[\"articles\"]\n",
    "\n",
    "print(\"articles_type : \", type(articles), \"articles_len : \",  len(articles))\n",
    "\n",
    "data_res = []\n",
    "for arti in articles:\n",
    "    data_dict = dict()\n",
    "    arti_url = arti[\"url\"]\n",
    "    arti_time = arti[\"publishedAt\"]\n",
    "    arti_desc = arti[\"description\"]\n",
    "    arti_title = arti[\"title\"]\n",
    "    arti_source = arti[\"source\"]\n",
    "    \n",
    "    data_dict[\"time\"] = arti_time\n",
    "    data_dict[\"title\"] = arti_title\n",
    "    data_res.append(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 100\n",
      "2018-02-13T00:43:41Z\n",
      "2018-02-13T18:06:10Z\n",
      "2018-02-17T17:23:38Z\n",
      "2018-02-18T07:52:02Z\n",
      "2018-02-20T13:30:00Z\n",
      "2018-02-20T15:07:11Z\n",
      "2018-02-20T15:46:00Z\n",
      "2018-02-20T16:28:02Z\n",
      "2018-02-21T08:37:45Z\n",
      "2018-02-21T08:57:00Z\n",
      "2018-02-21T11:32:55Z\n",
      "2018-02-21T14:15:00Z\n",
      "2018-02-21T20:27:54Z\n",
      "2018-02-22T14:58:33Z\n",
      "2018-02-23T14:51:44Z\n",
      "2018-02-23T15:38:21Z\n",
      "2018-02-25T12:01:47Z\n",
      "2018-03-01T09:56:24Z\n",
      "2018-03-02T23:09:18Z\n",
      "2018-03-05T02:57:39Z\n",
      "2018-03-06T15:55:29Z\n",
      "2018-03-09T13:16:57Z\n",
      "2018-03-11T12:20:14Z\n",
      "2018-03-14T16:12:38Z\n",
      "2018-03-16T08:53:17Z\n",
      "2018-03-18T11:13:14Z\n",
      "2018-03-20T18:03:52Z\n",
      "2018-03-21T08:23:41Z\n",
      "2018-03-21T16:52:48Z\n",
      "2018-03-22T16:01:20Z\n"
     ]
    }
   ],
   "source": [
    "print(len(data_dict[\"title\"]), len(data_res))\n",
    "\n",
    "from operator import itemgetter\n",
    "newlist = sorted(data_res, key=itemgetter('time')) \n",
    "\n",
    "for da in newlist[:30]:\n",
    "    print(da[\"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # top-headlines 查询好像不是很好用\n",
    "\n",
    "# # /v2/top-headlines\n",
    "# url_params = {\"q\":\"google\", \"page\": 2, \"pageSize\": 100, \"apiKey\": API_KEY}\n",
    "\n",
    "# headlines_url = \"https://newsapi.org/v2/top-headlines?\"\n",
    "# r = requests.get(headlines_url, params=url_params)\n",
    "\n",
    "# rtext = json.loads(r.text)\n",
    "\n",
    "# status = rtext[\"status\"]\n",
    "# articles = rtext[\"articles\"]\n",
    "# totalResults = rtext[\"totalResults\"]\n",
    "\n",
    "# print(\"status : \", status, \"  |  totalResults : \", totalResults)\n",
    "# articles = rtext[\"articles\"]\n",
    "\n",
    "# print(\"articles_type : \", type(articles), \"articles_len : \",  len(articles))\n",
    "\n",
    "# data_res = []\n",
    "# for arti in articles:\n",
    "#     data_dict = dict()\n",
    "#     arti_url = arti[\"url\"]\n",
    "#     arti_time = arti[\"publishedAt\"]\n",
    "#     arti_desc = arti[\"description\"]\n",
    "#     arti_title = arti[\"title\"]\n",
    "#     arti_source = arti[\"source\"]\n",
    "    \n",
    "#     data_dict[\"time\"] = arti_time\n",
    "#     data_dict[\"title\"] = arti_title\n",
    "#     data_res.append(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 不能用，因为和http的api不配套，有些参数没办法用，比如pageSize和from\n",
    "# # /v2/top-headlines\n",
    "# top_headlines = newsapi.get_top_headlines(q=\"stock\", sources='CNN')  ## cnn-money\n",
    "# print(top_headlines)\n",
    "\n",
    "# top_headlines = newsapi.get_everything(q=\"facebook\" , to='2018-05-08', pageSize = 100,sources='bloomberg')\n",
    "\n",
    "# top_headlines = newsapi.get_everything(to='2017-01-15', sources='reuters')\n",
    "# print(top_headlines)\n",
    "\n",
    "# top_headlines = newsapi.get_everything(to='2017-01-15', sources='MSNBC')\n",
    "# print(top_headlines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
